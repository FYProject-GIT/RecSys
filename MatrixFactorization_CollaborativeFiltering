python
Python 2.7.15rc1 (default, Nov 12 2018, 14:31:15) 
[GCC 7.3.0] on linux2
Type "help", "copyright", "credits" or "license" for more information.
>>> import pandas as pd
>>> import numpy as np
>>> from scipy.sparse import csr_matrix
>>> import sklearn
>>> from sklearn.decomposition import TruncatedSVD
>>> 
>>> book = pd.read_csv('BX-Books.csv', sep=';', error_bad_lines=False, encoding="latin-1")
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/sagar/.local/lib/python2.7/site-packages/pandas/io/parsers.py", line 678, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "/home/sagar/.local/lib/python2.7/site-packages/pandas/io/parsers.py", line 440, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/sagar/.local/lib/python2.7/site-packages/pandas/io/parsers.py", line 787, in __init__
    self._make_engine(self.engine)
  File "/home/sagar/.local/lib/python2.7/site-packages/pandas/io/parsers.py", line 1014, in _make_engine
    self._engine = CParserWrapper(self.f, **self.options)
  File "/home/sagar/.local/lib/python2.7/site-packages/pandas/io/parsers.py", line 1708, in __init__
    self._reader = parsers.TextReader(src, **kwds)
  File "pandas/_libs/parsers.pyx", line 384, in pandas._libs.parsers.TextReader.__cinit__
  File "pandas/_libs/parsers.pyx", line 695, in pandas._libs.parsers.TextReader._setup_parser_source
IOError: File BX-Books.csv does not exist
>>> book.columns = ['ISBN', 'bookTitle', 'bookAuthor', 'yearOfPublication', 'publisher', 'imageUrlS', 'imageUrlM', 'imageUrlL']
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'book' is not defined
>>> user = pd.read_csv('BX-Users.csv', sep=';', error_bad_lines=False, encoding="latin-1")
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/sagar/.local/lib/python2.7/site-packages/pandas/io/parsers.py", line 678, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "/home/sagar/.local/lib/python2.7/site-packages/pandas/io/parsers.py", line 440, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/sagar/.local/lib/python2.7/site-packages/pandas/io/parsers.py", line 787, in __init__
    self._make_engine(self.engine)
  File "/home/sagar/.local/lib/python2.7/site-packages/pandas/io/parsers.py", line 1014, in _make_engine
    self._engine = CParserWrapper(self.f, **self.options)
  File "/home/sagar/.local/lib/python2.7/site-packages/pandas/io/parsers.py", line 1708, in __init__
    self._reader = parsers.TextReader(src, **kwds)
  File "pandas/_libs/parsers.pyx", line 384, in pandas._libs.parsers.TextReader.__cinit__
  File "pandas/_libs/parsers.pyx", line 695, in pandas._libs.parsers.TextReader._setup_parser_source
IOError: File BX-Users.csv does not exist
>>> user.columns = ['userID', 'Location', 'Age']
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'user' is not defined
>>> rating = pd.read_csv('BX-Book-Ratings.csv', sep=';', error_bad_lines=False, encoding="latin-1")
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/sagar/.local/lib/python2.7/site-packages/pandas/io/parsers.py", line 678, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "/home/sagar/.local/lib/python2.7/site-packages/pandas/io/parsers.py", line 440, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/sagar/.local/lib/python2.7/site-packages/pandas/io/parsers.py", line 787, in __init__
    self._make_engine(self.engine)
  File "/home/sagar/.local/lib/python2.7/site-packages/pandas/io/parsers.py", line 1014, in _make_engine
    self._engine = CParserWrapper(self.f, **self.options)
  File "/home/sagar/.local/lib/python2.7/site-packages/pandas/io/parsers.py", line 1708, in __init__
    self._reader = parsers.TextReader(src, **kwds)
  File "pandas/_libs/parsers.pyx", line 384, in pandas._libs.parsers.TextReader.__cinit__
  File "pandas/_libs/parsers.pyx", line 695, in pandas._libs.parsers.TextReader._setup_parser_source
IOError: File BX-Book-Ratings.csv does not exist
>>> user = pd.read_csv('BX-Users.csv', sep=';', error_bad_lines=False, encoding="latin-1")exit
  File "<stdin>", line 1
    user = pd.read_csv('BX-Users.csv', sep=';', error_bad_lines=False, encoding="latin-1")exit
                                                                                             ^
SyntaxError: invalid syntax
>>> exit()
sagar@sagar-Inspiron-5559:~$ 
sagar@sagar-Inspiron-5559:~$ 
sagar@sagar-Inspiron-5559:~$ import pandas as pd
^L^Csagar@sagar-Inspiron-5559:~$ 



































sagar@sagar-Inspiron-5559:~$ python
Python 2.7.15rc1 (default, Nov 12 2018, 14:31:15) 
[GCC 7.3.0] on linux2
Type "help", "copyright", "credits" or "license" for more information.
>>> 
>>> import pandas as pd
>>> import numpy as np
>>> from scipy.sparse import csr_matrix
>>> import sklearn
>>> from sklearn.decomposition import TruncatedSVD
>>> book = pd.read_csv('BX-Books.csv', sep=';', error_bad_lines=False, encoding="latin-1")
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/sagar/.local/lib/python2.7/site-packages/pandas/io/parsers.py", line 678, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "/home/sagar/.local/lib/python2.7/site-packages/pandas/io/parsers.py", line 440, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/sagar/.local/lib/python2.7/site-packages/pandas/io/parsers.py", line 787, in __init__
    self._make_engine(self.engine)
  File "/home/sagar/.local/lib/python2.7/site-packages/pandas/io/parsers.py", line 1014, in _make_engine
    self._engine = CParserWrapper(self.f, **self.options)
  File "/home/sagar/.local/lib/python2.7/site-packages/pandas/io/parsers.py", line 1708, in __init__
    self._reader = parsers.TextReader(src, **kwds)
  File "pandas/_libs/parsers.pyx", line 384, in pandas._libs.parsers.TextReader.__cinit__
  File "pandas/_libs/parsers.pyx", line 695, in pandas._libs.parsers.TextReader._setup_parser_source
IOError: File BX-Books.csv does not exist
>>> book = pd.read_csv('Books.csv', sep=';', error_bad_lines=False, encoding="latin-1")
Skipping line 6452: expected 8 fields, saw 9
Skipping line 43667: expected 8 fields, saw 10
Skipping line 51751: expected 8 fields, saw 9

Skipping line 92038: expected 8 fields, saw 9
Skipping line 104319: expected 8 fields, saw 9
Skipping line 121768: expected 8 fields, saw 9

Skipping line 144058: expected 8 fields, saw 9
Skipping line 150789: expected 8 fields, saw 9
Skipping line 157128: expected 8 fields, saw 9
Skipping line 180189: expected 8 fields, saw 9
Skipping line 185738: expected 8 fields, saw 9

Skipping line 209388: expected 8 fields, saw 9
Skipping line 220626: expected 8 fields, saw 9
Skipping line 227933: expected 8 fields, saw 11
Skipping line 228957: expected 8 fields, saw 10
Skipping line 245933: expected 8 fields, saw 9
Skipping line 251296: expected 8 fields, saw 9
Skipping line 259941: expected 8 fields, saw 9
Skipping line 261529: expected 8 fields, saw 9

sys:1: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.
>>> book.columns = ['ISBN', 'bookTitle', 'bookAuthor', 'yearOfPublication', 'publisher', 'imageUrlS', 'imageUrlM', 'imageUrlL']
>>> user = pd.read_csv('BX-Users.csv', sep=';', error_bad_lines=False, encoding="latin-1")
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/sagar/.local/lib/python2.7/site-packages/pandas/io/parsers.py", line 678, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "/home/sagar/.local/lib/python2.7/site-packages/pandas/io/parsers.py", line 440, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/sagar/.local/lib/python2.7/site-packages/pandas/io/parsers.py", line 787, in __init__
    self._make_engine(self.engine)
  File "/home/sagar/.local/lib/python2.7/site-packages/pandas/io/parsers.py", line 1014, in _make_engine
    self._engine = CParserWrapper(self.f, **self.options)
  File "/home/sagar/.local/lib/python2.7/site-packages/pandas/io/parsers.py", line 1708, in __init__
    self._reader = parsers.TextReader(src, **kwds)
  File "pandas/_libs/parsers.pyx", line 384, in pandas._libs.parsers.TextReader.__cinit__
  File "pandas/_libs/parsers.pyx", line 695, in pandas._libs.parsers.TextReader._setup_parser_source
IOError: File BX-Users.csv does not exist
>>> user = pd.read_csv('users.csv', sep=';', error_bad_lines=False, encoding="latin-1")
>>> user.columns = ['userID', 'Location', 'Age']
>>> rating = pd.read_csv('BX-Book-Ratings.csv', sep=';', error_bad_lines=False, encoding="latin-1")
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/sagar/.local/lib/python2.7/site-packages/pandas/io/parsers.py", line 678, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "/home/sagar/.local/lib/python2.7/site-packages/pandas/io/parsers.py", line 440, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/sagar/.local/lib/python2.7/site-packages/pandas/io/parsers.py", line 787, in __init__
    self._make_engine(self.engine)
  File "/home/sagar/.local/lib/python2.7/site-packages/pandas/io/parsers.py", line 1014, in _make_engine
    self._engine = CParserWrapper(self.f, **self.options)
  File "/home/sagar/.local/lib/python2.7/site-packages/pandas/io/parsers.py", line 1708, in __init__
    self._reader = parsers.TextReader(src, **kwds)
  File "pandas/_libs/parsers.pyx", line 384, in pandas._libs.parsers.TextReader.__cinit__
  File "pandas/_libs/parsers.pyx", line 695, in pandas._libs.parsers.TextReader._setup_parser_source
IOError: File BX-Book-Ratings.csv does not exist
>>> rating = pd.read_csv('ratings.csv', sep=';', error_bad_lines=False, encoding="latin-1")
>>> rating.columns = ['userID', 'ISBN', 'bookRating']
>>> rating.head()
   userID        ISBN  bookRating
0  276725  034545104X           0
1  276726  0155061224           5
2  276727  0446520802           0
3  276729  052165615X           3
4  276729  0521795028           6
>>> user.head()
   userID                            Location   Age
0       1                  nyc, new york, usa   NaN
1       2           stockton, california, usa  18.0
2       3     moscow, yukon territory, russia   NaN
3       4           porto, v.n.gaia, portugal  17.0
4       5  farnborough, hants, united kingdom   NaN
>>> book.head()
  ...
0 ...
1 ...
2 ...
3 ...
4 ...

[5 rows x 8 columns]
>>> combine_book_rating = pd.merge(rating, book, on='ISBN')
>>> columns = ['yearOfPublication', 'publisher', 'bookAuthor', 'imageUrlS', 'imageUrlM', 'imageUrlL']
>>> combine_book_rating = combine_book_rating.drop(columns, axis=1)
>>> combine_book_rating.head()
   userID          ...                      bookTitle
0  276725          ...           Flesh Tones: A Novel
1    2313          ...           Flesh Tones: A Novel
2    6543          ...           Flesh Tones: A Novel
3    8680          ...           Flesh Tones: A Novel
4   10314          ...           Flesh Tones: A Novel

[5 rows x 4 columns]
>>> combine_book_rating = combine_book_rating.dropna(axis = 0, subset = ['bookTitle'])
>>> book_ratingCount = (combine_book_rating.
...      groupby(by = ['bookTitle'])['bookRating'].
...      count().
...      reset_index().
...      rename(columns = {'bookRating': 'totalRatingCount'})
...      [['bookTitle', 'totalRatingCount']]
...     )
>>> book_ratingCount.head()
  ...
0 ...
1 ...
2 ...
3 ...
4 ...

[5 rows x 2 columns]
>>> rating_with_totalRatingCount = combine_book_rating.merge(book_ratingCount, left_on = 'bookTitle', right_on = 'bookTitle', how = 'left')
>>> rating_with_totalRatingCount.head()
   userID       ...        totalRatingCount
0  276725       ...                      60
1    2313       ...                      60
2    6543       ...                      60
3    8680       ...                      60
4   10314       ...                      60

[5 rows x 5 columns]
>>> pd.set_option('display.float_format', lambda x: '%.3f' % x)
>>> print(book_ratingCount['totalRatingCount'].describe())
count   241071.000
mean         4.277
std         16.739
min          1.000
25%          1.000
50%          1.000
75%          3.000
max       2502.000
Name: totalRatingCount, dtype: float64
>>> print(book_ratingCount['totalRatingCount'].quantile(np.arange(.9, 1, .01)))
0.900    7.000
0.910    8.000
0.920    9.000
0.930   10.000
0.940   11.000
0.950   13.000
0.960   16.000
0.970   20.000
0.980   29.000
0.990   50.000
Name: totalRatingCount, dtype: float64
>>> popularity_threshold = 50
>>> rating_popular_book = rating_with_totalRatingCount.query('totalRatingCount >= @popularity_threshold')
>>> rating_popular_book.head()
   userID       ...        totalRatingCount
0  276725       ...                      60
1    2313       ...                      60
2    6543       ...                      60
3    8680       ...                      60
4   10314       ...                      60

[5 rows x 5 columns]
>>> 
>>> combined = rating_popular_book.merge(user, left_on = 'userID', right_on = 'userID', how = 'left')
>>> 
>>> us_canada_user_rating = combined[combined['Location'].str.contains("usa|canada")]
>>> us_canada_user_rating=us_canada_user_rating.drop('Age', axis=1)
>>> us_canada_user_rating.head()
  ...
0 ...
1 ...
2 ...
3 ...
4 ...

[5 rows x 6 columns]
>>> if not us_canada_user_rating[us_canada_user_rating.duplicated(['userID', 'bookTitle'])].empty:
...     initial_rows = us_canada_user_rating.shape[0]
... 
>>>     print('Initial dataframe shape {0}'.format(us_canada_user_rating.shape))
  File "<stdin>", line 1
    print('Initial dataframe shape {0}'.format(us_canada_user_rating.shape))
    ^
IndentationError: unexpected indent
>>>     us_canada_user_rating = us_canada_user_rating.drop_duplicates(['userID', 'bookTitle'])
  File "<stdin>", line 1
    us_canada_user_rating = us_canada_user_rating.drop_duplicates(['userID', 'bookTitle'])
    ^
IndentationError: unexpected indent
>>>     current_rows = us_canada_user_rating.shape[0]
  File "<stdin>", line 1
    current_rows = us_canada_user_rating.shape[0]
    ^
IndentationError: unexpected indent
>>>     print('New dataframe shape {0}'.format(us_canada_user_rating.shape))
  File "<stdin>", line 1
    print('New dataframe shape {0}'.format(us_canada_user_rating.shape))
    ^
IndentationError: unexpected indent
>>>     print('Removed {0} rows'.format(initial_rows - current_rows))
  File "<stdin>", line 1
    print('Removed {0} rows'.format(initial_rows - current_rows))
    ^
IndentationError: unexpected indent
>>> 
>>> if not us_canada_user_rating[us_canada_user_rating.duplicated(['userID', 'bookTitle'])].empty:
...     initial_rows = us_canada_user_rating.shape[0]
... if not us_canada_user_rating[us_canada_user_rating.duplicated(['userID', 'bookTitle'])].empty:
  File "<stdin>", line 3
    if not us_canada_user_rating[us_canada_user_rating.duplicated(['userID', 'bookTitle'])].empty:
     ^
SyntaxError: invalid syntax
>>> if not us_canada_user_rating[us_canada_user_rating.duplicated(['userID', 'bookTitle'])].empty:
... 
  File "<stdin>", line 2
    
    ^
IndentationError: expected an indented block
>>> if not us_canada_user_rating[us_canada_user_rating.duplicated(['userID', 'bookTitle'])].empty:
...     initial_rows = us_canada_user_rating.shape[0]
... print('Initial dataframe shape {0}'.format(us_canada_user_rating.shape))    us_canada_user_rating = us_canada_user_rating.drop_duplicates(['userID', 'bookTitle'])
  File "<stdin>", line 3
    print('Initial dataframe shape {0}'.format(us_canada_user_rating.shape))    us_canada_user_rating = us_canada_user_rating.drop_duplicates(['userID', 'bookTitle'])
        ^
SyntaxError: invalid syntax
>>> print('Initial dataframe shape {0}'.format(us_canada_user_rating.shape))    us_canada_user_rating = us_canada_user_rating.drop_duplicates(['userID', 'bookTitle'])
  File "<stdin>", line 1
    print('Initial dataframe shape {0}'.format(us_canada_user_rating.shape))    us_canada_user_rating = us_canada_user_rating.drop_duplicates(['userID', 'bookTitle'])
                                                                                                    ^
SyntaxError: invalid syntax
>>> if not us_canada_user_rating[us_canada_user_rating.duplicated(['userID', 'bookTitle'])].empty:
...     initial_rows = us_canada_user_rating.shape[0]
...     print('Initial dataframe shape {0}'.format(us_canada_user_rating.shape))
...     us_canada_user_rating = us_canada_user_rating.drop_duplicates(['userID', 'bookTitle'])
...     current_rows = us_canada_user_rating.shape[0]
...     print('New dataframe shape {0}'.format(us_canada_user_rating.shape))
...     print('Removed {0} rows'.format(initial_rows - current_rows))
... 
Initial dataframe shape (251615, 6)
New dataframe shape (248949, 6)
Removed 2666 rows
>>> us_canada_user_rating_pivot = us_canada_user_rating.pivot(index = 'bookTitle', columns = 'userID', values = 'bookRating').fillna(0)
>>> us_canada_user_rating_matrix = csr_matrix(us_canada_user_rating_pivot.values)
>>> from sklearn.neighbors import NearestNeighbors
>>> model_knn = NearestNeighbors(metric = 'cosine', algorithm = 'brute')
>>> model_knn.fit(us_canada_user_rating_matrix)
NearestNeighbors(algorithm='brute', leaf_size=30, metric='cosine',
         metric_params=None, n_jobs=1, n_neighbors=5, p=2, radius=1.0)
>>> 
>>> query_index = np.random.choice(us_canada_user_rating_pivot.shape[0])
>>> distances, indices = model_knn.kneighbors(us_canada_user_rating_pivot.iloc[query_index, :].reshape(1, -1), n_neighbors = 6)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/sagar/.local/lib/python2.7/site-packages/pandas/core/generic.py", line 4372, in __getattr__
    return object.__getattribute__(self, name)
AttributeError: 'Series' object has no attribute 'reshape'
>>> distances, indices = model_knn.kneighbors(us_canada_user_rating_pivot.iloc[query_index, :].values.reshape(1, -1), n_neighbors = 6)
>>> for i in range(0, len(distances.flatten())):
...  if i == 0:
...         print('Recommendations for {0}:\n'.format(us_canada_user_rating_pivot.index[query_index]))
...     else:
  File "<stdin>", line 4
    else:
        ^
IndentationError: unindent does not match any outer indentation level
>>> for i in range(0, len(distances.flatten())):
...  if i == 0:
...         print('Recommendations for {0}:\n'.format(us_canada_user_rating_pivot.index[query_index]))
... else:
...         print('{0}: {1}, with distance of {2}:'.format(i, us_canada_user_rating_pivot.index[indices.flatten()[i]], distances.flatten()[i]))
... 
Recommendations for Final Appeal:

5: Deep South, with distance of 0.897687154318:
>>> us_canada_user_rating_pivot2 = us_canada_user_rating.pivot(index = 'userID', columns = 'bookTitle', values = 'bookRating').fillna(0)
>>> us_canada_user_rating_pivot2.head()
us_canada_user_rating_pivot2.shape
bookTitle  10 Lb. Penalty    ...     stardust
userID                       ...             
8                   0.000    ...        0.000
9                   0.000    ...        0.000
14                  0.000    ...        0.000
16                  0.000    ...        0.000
17                  0.000    ...        0.000

[5 rows x 2442 columns]
>>> us_canada_user_rating_pivot2.shape
(40017, 2442)
>>> X = us_canada_user_rating_pivot2.values.T
>>> X.shape
(2442, 40017)
>>> import sklearn
>>> from sklearn.decomposition import TruncatedSVD
>>> SVD = TruncatedSVD(n_components=12, random_state=17)
>>> matrix = SVD.fit_transform(X)
>>> matrix.shape
(2442, 12)
>>> import warnings
>>> warnings.filterwarnings("ignore",category =RuntimeWarning)
>>> corr = np.corrcoef(matrix)
>>> corr.shape
(2442, 2442)
>>> us_canada_book_title = us_canada_user_rating_pivot2.columns
>>> us_canada_book_list = list(us_canada_book_title)
>>> coffey_hands = us_canada_book_list.index("The Green Mile: Coffey's Hands (Green Mile Series)")
>>> print(coffey_hands)
1906
>>> corr_coffey_hands  = corr[coffey_hands]
>>> list(us_canada_book_title[(corr_coffey_hands<1.0) & (corr_coffey_hands>0.9)])
[u'Needful Things', u'The Bachman Books: Rage, the Long Walk, Roadwork, the Running Man', u'The Green Mile: Coffey on the Mile (Green Mile Series)', u'The Green Mile: Night Journey (Green Mile Series)', u'The Green Mile: The Bad Death of Eduard Delacroix (Green Mile Series)', u'The Green Mile: The Mouse on the Mile (Green Mile Series)', u'The Shining', u'The Two Dead Girls (Green Mile Series)']
>>> 
